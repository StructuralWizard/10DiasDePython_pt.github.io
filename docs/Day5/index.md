---
title: Dia 5 Web Scraping com Beautiful Soup e Selenium
layout: default
nav_order: 6
has_children: false
nav_exclude: false
---

# Dia 5. Web Scraping. üï∑Ô∏è Beautiful Soup e Selenium
{: .no_toc }

Bem-vindo ao Dia 5! Hoje, voc√™ aprender√° a extrair dados de sites usando Python. Come√ßaremos com o Beautiful Soup para p√°ginas est√°ticas e, em seguida, avan√ßaremos para o Selenium para sites din√¢micos e interativos. Ao final, voc√™ ser√° capaz de coletar dados da web para seus pr√≥prios projetos!

---

<details open markdown="block">
  <summary>
    √çndice
  </summary>
  {: .text-delta }
1. TOC
{:toc}
</details>

---

## üå± O que √© Web Scraping?
Web scraping √© o processo de coletar informa√ß√µes de sites automaticamente. √â √∫til para coletar dados que n√£o est√£o dispon√≠veis por meio de uma API.

- **Beautiful Soup**: Analisa documentos HTML e XML. √ìtimo para p√°ginas est√°ticas.
- **Selenium**: Automatiza navegadores. √ötil para sites din√¢micos que exigem intera√ß√£o (cliques, digita√ß√£o, etc.).

---

## ü•£ No√ß√µes B√°sicas do Beautiful Soup <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>
Para analisar e navegar em HTML/XML com Python
Requer: `beautifulsoup4` e um analisador como `lxml` ou o `html.parser` embutido do Python.

### üß© O que voc√™ pode fazer com o Beautiful Soup?
Aqui est√° um resumo de suas principais capacidades:

* **Analisar HTML e XML:** O Beautiful Soup pega o conte√∫do HTML ou XML bruto e o transforma em uma "√°rvore de an√°lise" naveg√°vel, composta por objetos Python. Essa √°rvore torna simples o acesso e a manipula√ß√£o de partes espec√≠ficas do documento.

* **Navegar na √Årvore de An√°lise:** Voc√™ pode se mover facilmente pela estrutura HTML/XML:
    * **Por nome da tag:** Encontre elementos como `<div>`, `<a>` ou `<p>`.
    * **Por atributos:** Localize elementos com base em seu `id`, `class`, `href` ou qualquer outro atributo.
    * **Por conte√∫do de texto:** Pesquise por palavras ou frases espec√≠ficas dentro dos elementos.
    * **Usando relacionamentos:** Navegue para cima (pai), para baixo (filhos, descendentes) ou para os lados (irm√£os) na √°rvore.

* **Pesquisar por Elementos Espec√≠ficos:** O Beautiful Soup oferece m√©todos poderosos como `find()` (para obter a primeira correspond√™ncia) e `find_all()` (para obter todas as correspond√™ncias) para identificar os dados exatos que voc√™ est√° procurando. Voc√™ pode combinar isso com v√°rios filtros (nomes de tags, atributos, seletores CSS, express√µes regulares ou at√© mesmo fun√ß√µes personalizadas) para uma sele√ß√£o precisa.

* **Extrair Dados:** Depois de encontrar os elementos que deseja, voc√™ pode extrair facilmente:
    * **Conte√∫do de texto:** Obtenha o texto vis√≠vel dentro de uma tag (por exemplo, `soup.title.string`).
    * **Valores de atributos:** Acesse os valores de atributos como `href` de uma tag `<a>` ou `src` de uma tag `<img>`.

* **Lidar com HTML Malformado:** Uma das for√ßas do Beautiful Soup √© sua capacidade de lidar com "sopa de tags"‚ÄîHTML mal estruturado ou incompleto. Ele tenta fazer sentido e construir uma √°rvore de an√°lise utiliz√°vel.

* **Integrar com Outras Bibliotecas:**
    * **Requests:** Frequentemente usado com a biblioteca `requests` para buscar o conte√∫do HTML de uma URL antes que o Beautiful Soup o analise.
    * **Selenium:** Para sites din√¢micos que dependem muito de JavaScript para renderiza√ß√£o, voc√™ pode usar o Selenium (uma ferramenta de automa√ß√£o de navegador) para carregar a p√°gina e, em seguida, passar o HTML renderizado para o Beautiful Soup para an√°lise.
    * **Pandas:** Os dados extra√≠dos podem ser facilmente estruturados e armazenados em DataFrames do Pandas para an√°lise posterior ou exporta√ß√£o para formatos como CSV ou Excel.

---

### üß∞ Usos Comuns do Beautiful Soup

O Beautiful Soup √© usado principalmente para:

* **Web Scraping:** Este √© seu principal prop√≥sito. Voc√™ pode us√°-lo para:
    * Coletar informa√ß√µes de produtos (nomes, pre√ßos, descri√ß√µes) de sites de com√©rcio eletr√¥nico.
    * Extrair artigos de not√≠cias, postagens de blog ou artigos de pesquisa.
    * Coletar listas de empregos ou dados imobili√°rios.
    * Realizar an√°lise de sentimento raspando avalia√ß√µes ou coment√°rios.
* **Minera√ß√£o de Dados:** Transformar dados da web n√£o estruturados em conjuntos de dados organizados para an√°lise.
* **Agrega√ß√£o de Conte√∫do:** Construir ferramentas que extraem conte√∫do de v√°rias fontes online para um local centralizado.

Em resumo, o Beautiful Soup capacita os desenvolvedores Python a interagir programaticamente com o conte√∫do da web, tornando-o uma ferramenta essencial para quem deseja extrair e trabalhar com dados da internet.

### üì¶ Instale os pacotes necess√°rios
```bash
pip install beautifulsoup4 requests lxml
```

### üìÑ Exemplo: Raspando um Arquivo HTML Local
Suponha que voc√™ tenha um arquivo chamado `website.html`:

```python
from bs4 import BeautifulSoup

with open("website.html", encoding="utf-8") as file:
    contents = file.read()

soup = BeautifulSoup(contents, "html.parser")
print(soup.title)
```

### üßº Limpando HTML
```python
clean_text = soup.get_text(strip=True)
```

### üîç Encontrando Elementos
Voc√™ pode procurar por tags, classes, ids e muito mais:

```python
# Encontra a primeira tag <a>
anchor = soup.find("a")
print(anchor)

# Encontra todas as tags <a>
all_anchors = soup.find_all("a")
for tag in all_anchors:
    # .getText() obt√©m o texto vis√≠vel dentro da tag
    print(tag.getText())
    # .get() recupera o valor de um atributo (por exemplo, href)
    print(tag.get("href"))
```

#### Pesquisar por atributos (id, classe, etc.)
```python
# Encontrar por id
heading = soup.find(name="h1", id="name")

# Encontrar por classe (nota: use class_ porque 'class' √© uma palavra reservada)
section = soup.find(name="h3", class_="heading")

# Encontrar todos os elementos com uma classe espec√≠fica
items = soup.find_all(class_="item")
```

#### Pesquisar usando seletores CSS
```python
# Use .select() para seletores CSS
links = soup.select("a.storylink")  # Todas as tags <a> com a classe 'storylink'
ids = soup.select("#main")          # Elemento com o id 'main'
classes = soup.select(".heading")   # Todos os elementos com a classe 'heading'
```

### üå≥ Navegando na √Årvore
```python
tag.name         # Nome da tag
tag.attrs        # Atributos da tag como dict
tag['href']      # Atributo espec√≠fico

tag.text         # Todo o texto dentro da tag (recursivo)
tag.string       # Apenas a string direta
tag.parent
tag.children      # Gerador de filhos
tag.contents      # Lista de filhos
tag.next_sibling
tag.previous_sibling

```


### üîó Navegando e Seguindo Links
Voc√™ pode extrair e seguir links combinando `.get("href")` com `requests`:

```python
for tag in soup.find_all("a"):
    link = tag.get("href")
    if link and link.startswith("http"):
        print("Seguindo:", link)
        # Voc√™ pode buscar a p√°gina vinculada com requests.get(link)
```

Para mais refer√™ncias, consulte a <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank">documenta√ß√£o</a>.


---

## üåê Raspando Sites ao Vivo <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

Para raspar um site ao vivo, use a biblioteca `requests` para buscar a p√°gina:

```python
import requests
from bs4 import BeautifulSoup

url = "https://news.ycombinator.com/"
response = requests.get(url)
webpage = response.text
soup = BeautifulSoup(webpage, "html.parser")

# Obt√©m todos os t√≠tulos dos artigos
titles = soup.find_all("a", class_="storylink")
for title in titles:
    print(title.getText())
```

---

## ‚öñÔ∏è Web Scraping √© Legal? <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

- Raspe apenas dados p√∫blicos.
- Respeite o `robots.txt` e os termos do site.
- N√£o sobrecarregue os servidores (adicione atrasos se estiver raspando muitas p√°ginas).
- Use os dados raspados de forma respons√°vel.

---

## ü§ñ Selenium para Sites Din√¢micos <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

Alguns sites carregam conte√∫do com JavaScript ou exigem intera√ß√£o. O Selenium permite que voc√™ controle um navegador real para lidar com esses casos.

Ao contr√°rio do Beautiful Soup, que se limita a raspar dados, o Selenium permite a intera√ß√£o com p√°ginas da web, como digitar, clicar e rolar. Ele permite a automa√ß√£o de a√ß√µes cont√≠nuas e fluxos de trabalho inteiros de uma determinada tarefa ou trabalho. Ele efetivamente controla um navegador para realizar a√ß√µes como um usu√°rio humano.

O Selenium pode automatizar quase tudo que um humano pode fazer em um site, como preencher formul√°rios, transferir informa√ß√µes ou jogar jogos baseados na web.

### üöó Introdu√ß√£o ao Selenium WebDriver

* **O que √©:** O Selenium WebDriver √© uma ferramenta de automa√ß√£o e teste bem conhecida para desenvolvedores da web.
* **Por que us√°-lo (em vez do Beautiful Soup):** Ao contr√°rio do Beautiful Soup, que se limita a raspar dados, o Selenium permite a intera√ß√£o com p√°ginas da web, como digitar, clicar e rolar. Ele permite a automa√ß√£o de a√ß√µes cont√≠nuas e fluxos de trabalho inteiros de uma determinada tarefa ou trabalho. Ele efetivamente controla um navegador para realizar a√ß√µes como um usu√°rio humano.
* **Capacidades:** O Selenium pode automatizar quase tudo que um humano pode fazer em um site, como preencher formul√°rios, transferir informa√ß√µes ou jogar jogos baseados na web.

### üîß Instala√ß√£o e Configura√ß√£o do Selenium

1.  **Instale o Navegador Chrome:** Embora o Selenium funcione com outros navegadores como Firefox ou Safari, o Chrome √© recomendado para consist√™ncia e uso das Ferramentas de Desenvolvedor do Chrome. Baixe o driver do Chrome em [chromedriver.chromium.org](https://chromedriver.chromium.org/downloads) e coloque-o em seu PATH.
2.  **Instale o Pacote Selenium:**
    * Importe `selenium` em seu arquivo Python (por exemplo, `main.py`).
    * Instale o pacote usando a op√ß√£o de l√¢mpada fornecida em seu IDE.
```bash
pip install selenium
```
3.  **Importe o M√≥dulo WebDriver:** Altere a declara√ß√£o de importa√ß√£o para `from selenium import webdriver`.
4.  **Crie uma Inst√¢ncia do Driver:** Inicialize um objeto de driver do Chrome: `driver = webdriver.Chrome()`.
    * **Chromedriver:** Ele atua como uma ponte entre o c√≥digo Selenium –∏ o navegador Chrome, dizendo ao Selenium como interagir com o navegador. Existem diferentes drivers para diferentes navegadores (por exemplo, Safari, Firefox).
5.  **Controle do Navegador:**
    * `driver.close()`: Fecha a aba ativa.
    * `driver.quit()`: Encerra o navegador inteiro. √â prefer√≠vel usar `quit()` ap√≥s concluir as tarefas para garantir uma nova inst√¢ncia do navegador para futuras execu√ß√µes.

### üîé Exemplo: Abrir uma P√°gina e Encontrar um Elemento
```python
from selenium import webdriver
from selenium.webdriver.common.by import By
import time as time_module

# Inicia o navegador
browser = webdriver.Chrome()
browser.get("https://www.python.org")

# Encontra elementos
event_times = browser.find_elements(By.CSS_SELECTOR, ".event-widget time")
event_names = browser.find_elements(By.CSS_SELECTOR, ".event-widget li a")

for time, name in zip(event_times, event_names):
    print(time.text, name.text)

# Espera 3 segundos antes de fechar
time_module.sleep(3)

browser.quit()
```

### üîç Encontrando e Selecionando Elementos em um Site

**Localizando Elementos:**

O Selenium oferece v√°rias estrat√©gias para encontrar elementos HTML em uma p√°gina da web. Depois de identificar um elemento com a ferramenta de inspe√ß√£o do navegador, voc√™ pode copiar seu XPath ou outro identificador e us√°-lo com:

* **M√©todo `find_element()`:** Usado para encontrar um √∫nico elemento.
* **Classe `By`:** Importante para especificar a estrat√©gia de localiza√ß√£o (por exemplo, `By.CLASS_NAME`, `By.ID`, `By.NAME`, `By.LINK_TEXT`).
* **Exemplos:**
    * **Por Nome da Classe:** Para obter o pre√ßo de um item na Amazon, voc√™ pode encontrar elementos com classes como "a-price-whole" (para d√≥lares) e "a-price-fraction" (para centavos).
    * **Acessando o Conte√∫do de Texto:** Depois de encontrar um elemento, use `.text` para recuperar o conte√∫do de texto dentro desse elemento HTML.
    * **Por Nome:** √ötil para campos de entrada de formul√°rio.
    * **Por Texto do Link:** Especificamente para clicar em links pelo texto vis√≠vel.
* **M√©todo `find_elements()`:** Para cada m√©todo `find_element()`, existe um `find_elements()` correspondente que retorna uma lista de todos os elementos correspondentes.
* **Inspecionando Elementos:** Use as Ferramentas de Desenvolvedor do Chrome (bot√£o direito -> Inspecionar) para examinar a estrutura HTML e identificar IDs, nomes de classes ou outros atributos para elementos.

### üñ±Ô∏è Automatizando Intera√ß√µes (Digita√ß√£o e Cliques)

* **Clicando em Elementos:**
    * Depois de identificar um elemento, use o m√©todo `.click()` no objeto do elemento.
    * O Selenium pode clicar em links com base em seu `LINK_TEXT`.
* **Digitando em Campos de Entrada:**
    * Primeiro, encontre o elemento do campo de entrada.
    * Use o m√©todo `.send_keys()` no objeto do elemento, passando a string que voc√™ deseja digitar.
* **Enviando Teclas Especiais:** Para enviar teclas como `Enter` ou `Return`, importe a classe `Keys` de `selenium.webdriver.common.keys`.


---

## üìù Desafio: Raspar os Pr√≥ximos Eventos do Python <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

- Use o Selenium para abrir [python.org](https://www.python.org/)
- Extraia a data e o nome dos pr√≥ximos 5 eventos
- Armazene-os em um dicion√°rio como:

```python
events = {
    0: {"time": "2025-06-11", "name": "PyCon"},
    1: {"time": "2025-06-18", "name": "DjangoCon"},
    # ...
}
```

---

## üöÄ Resumo <a href="#top" class="back-to-top-link" aria-label="Back to Top">‚Üë</a>

- Use o Beautiful Soup para raspagem de HTML est√°tico
- Use o Selenium para sites din√¢micos e interativos
- Sempre respeite as regras e a √©tica do site

Agora voc√™ tem as ferramentas para coletar dados de quase qualquer site. Boa raspagem!
