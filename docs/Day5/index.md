---
title: Dia 5 Web Scraping com Beautiful Soup e Selenium
layout: default
nav_order: 6
has_children: false
nav_exclude: false
---

# Dia 5. Web Scraping. ğŸ•·ï¸ Beautiful Soup e Selenium
{: .no_toc }

Bem-vindo ao Dia 5! Hoje, vocÃª aprenderÃ¡ a extrair dados de sites usando Python. ComeÃ§aremos com o Beautiful Soup para pÃ¡ginas estÃ¡ticas e, em seguida, avanÃ§aremos para o Selenium para sites dinÃ¢micos e interativos. Ao final, vocÃª serÃ¡ capaz de coletar dados da web para seus prÃ³prios projetos!

---

<details open markdown="block">
  <summary>
    Ãndice
  </summary>
  {: .text-delta }
1. TOC
{:toc}
</details>

---

## ğŸŒ± O que Ã© Web Scraping?
Web scraping Ã© o processo de coletar informaÃ§Ãµes de sites automaticamente. Ã‰ Ãºtil para coletar dados que nÃ£o estÃ£o disponÃ­veis por meio de uma API.

- **Beautiful Soup**: Analisa documentos HTML e XML. Ã“timo para pÃ¡ginas estÃ¡ticas.
- **Selenium**: Automatiza navegadores. Ãštil para sites dinÃ¢micos que exigem interaÃ§Ã£o (cliques, digitaÃ§Ã£o, etc.).

---

## ğŸ¥£ NoÃ§Ãµes BÃ¡sicas do Beautiful Soup <a href="#top" class="back-to-top-link" aria-label="Back to Top">â†‘</a>
Para analisar e navegar em HTML/XML com Python
Requer: `beautifulsoup4` e um analisador como `lxml` ou o `html.parser` embutido do Python.

### ğŸ§© O que vocÃª pode fazer com o Beautiful Soup?
Aqui estÃ¡ um resumo de suas principais capacidades:

* **Analisar HTML e XML:** O Beautiful Soup pega o conteÃºdo HTML ou XML bruto e o transforma em uma "Ã¡rvore de anÃ¡lise" navegÃ¡vel, composta por objetos Python. Essa Ã¡rvore torna simples o acesso e a manipulaÃ§Ã£o de partes especÃ­ficas do documento.

* **Navegar na Ãrvore de AnÃ¡lise:** VocÃª pode se mover facilmente pela estrutura HTML/XML:
    * **Por nome da tag:** Encontre elementos como `<div>`, `<a>` ou `<p>`.
    * **Por atributos:** Localize elementos com base em seu `id`, `class`, `href` ou qualquer outro atributo.
    * **Por conteÃºdo de texto:** Pesquise por palavras ou frases especÃ­ficas dentro dos elementos.
    * **Usando relacionamentos:** Navegue para cima (pai), para baixo (filhos, descendentes) ou para os lados (irmÃ£os) na Ã¡rvore.

* **Pesquisar por Elementos EspecÃ­ficos:** O Beautiful Soup oferece mÃ©todos poderosos como `find()` (para obter a primeira correspondÃªncia) e `find_all()` (para obter todas as correspondÃªncias) para identificar os dados exatos que vocÃª estÃ¡ procurando. VocÃª pode combinar isso com vÃ¡rios filtros (nomes de tags, atributos, seletores CSS, expressÃµes regulares ou atÃ© mesmo funÃ§Ãµes personalizadas) para uma seleÃ§Ã£o precisa.

* **Extrair Dados:** Depois de encontrar os elementos que deseja, vocÃª pode extrair facilmente:
    * **ConteÃºdo de texto:** Obtenha o texto visÃ­vel dentro de uma tag (por exemplo, `soup.title.string`).
    * **Valores de atributos:** Acesse os valores de atributos como `href` de uma tag `<a>` ou `src` de uma tag `<img>`.

* **Lidar com HTML Malformado:** Uma das forÃ§as do Beautiful Soup Ã© sua capacidade de lidar com "sopa de tags"â€”HTML mal estruturado ou incompleto. Ele tenta fazer sentido e construir uma Ã¡rvore de anÃ¡lise utilizÃ¡vel.

* **Integrar com Outras Bibliotecas:**
    * **Requests:** Frequentemente usado com a biblioteca `requests` para buscar o conteÃºdo HTML de uma URL antes que o Beautiful Soup o analise.
    * **Selenium:** Para sites dinÃ¢micos que dependem muito de JavaScript para renderizaÃ§Ã£o, vocÃª pode usar o Selenium (uma ferramenta de automaÃ§Ã£o de navegador) para carregar a pÃ¡gina e, em seguida, passar o HTML renderizado para o Beautiful Soup para anÃ¡lise.
    * **Pandas:** Os dados extraÃ­dos podem ser facilmente estruturados e armazenados em DataFrames do Pandas para anÃ¡lise posterior ou exportaÃ§Ã£o para formatos como CSV ou Excel.

---

### ğŸ§° Usos Comuns do Beautiful Soup

O Beautiful Soup Ã© usado principalmente para:

* **Web Scraping:** Este Ã© seu principal propÃ³sito. VocÃª pode usÃ¡-lo para:
    * Coletar informaÃ§Ãµes de produtos (nomes, preÃ§os, descriÃ§Ãµes) de sites de comÃ©rcio eletrÃ´nico.
    * Extrair artigos de notÃ­cias, postagens de blog ou artigos de pesquisa.
    * Coletar listas de empregos ou dados imobiliÃ¡rios.
    * Realizar anÃ¡lise de sentimento raspando avaliaÃ§Ãµes ou comentÃ¡rios.
* **MineraÃ§Ã£o de Dados:** Transformar dados da web nÃ£o estruturados em conjuntos de dados organizados para anÃ¡lise.
* **AgregaÃ§Ã£o de ConteÃºdo:** Construir ferramentas que extraem conteÃºdo de vÃ¡rias fontes online para um local centralizado.

Em resumo, o Beautiful Soup capacita os desenvolvedores Python a interagir programaticamente com o conteÃºdo da web, tornando-o uma ferramenta essencial para quem deseja extrair e trabalhar com dados da internet.

### ğŸ“¦ Instale os pacotes necessÃ¡rios
```bash
pip install beautifulsoup4 requests lxml
```

### ğŸ“„ Exemplo: Raspando um Arquivo HTML Local
Suponha que vocÃª tenha um arquivo chamado `website.html`:

```python
from bs4 import BeautifulSoup

with open("website.html", encoding="utf-8") as file:
    contents = file.read()

soup = BeautifulSoup(contents, "html.parser")
print(soup.title)
```

### ğŸ§¼ Limpando HTML
```python
clean_text = soup.get_text(strip=True)
```

### ğŸ” Encontrando Elementos
VocÃª pode procurar por tags, classes, ids e muito mais:

```python
# Encontra a primeira tag <a>
anchor = soup.find("a")
print(anchor)

# Encontra todas as tags <a>
all_anchors = soup.find_all("a")
for tag in all_anchors:
    # .getText() obtÃ©m o texto visÃ­vel dentro da tag
    print(tag.getText())
    # .get() recupera o valor de um atributo (por exemplo, href)
    print(tag.get("href"))
```

#### Pesquisar por atributos (id, classe, etc.)
```python
# Encontrar por id
heading = soup.find(name="h1", id="name")

# Encontrar por classe (nota: use class_ porque 'class' Ã© uma palavra reservada)
section = soup.find(name="h3", class_="heading")

# Encontrar todos os elementos com uma classe especÃ­fica
items = soup.find_all(class_="item")
```

#### Pesquisar usando seletores CSS
```python
# Use .select() para seletores CSS
links = soup.select("a.storylink")  # Todas as tags <a> com a classe 'storylink'
ids = soup.select("#main")          # Elemento com o id 'main'
classes = soup.select(".heading")   # Todos os elementos com a classe 'heading'
```

### ğŸŒ³ Navegando na Ãrvore
```python
tag.name         # Nome da tag
tag.attrs        # Atributos da tag como dict
tag['href']      # Atributo especÃ­fico

tag.text         # Todo o texto dentro da tag (recursivo)
tag.string       # Apenas a string direta
tag.parent
tag.children      # Gerador de filhos
tag.contents      # Lista de filhos
tag.next_sibling
tag.previous_sibling

```


### ğŸ”— Navegando e Seguindo Links
VocÃª pode extrair e seguir links combinando `.get("href")` com `requests`:

```python
for tag in soup.find_all("a"):
    link = tag.get("href")
    if link and link.startswith("http"):
        print("Seguindo:", link)
        # VocÃª pode buscar a pÃ¡gina vinculada com requests.get(link)
```

Para mais referÃªncias, consulte a <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" target="_blank">documentaÃ§Ã£o</a>.


---

## ğŸŒ Raspando Sites ao Vivo <a href="#top" class="back-to-top-link" aria-label="Back to Top">â†‘</a>

Para raspar um site ao vivo, use a biblioteca `requests` para buscar a pÃ¡gina:

```python
import requests
from bs4 import BeautifulSoup

url = "https://news.ycombinator.com/"
response = requests.get(url)
webpage = response.text
soup = BeautifulSoup(webpage, "html.parser")

# ObtÃ©m todos os tÃ­tulos dos artigos
titles = soup.find_all("a", class_="storylink")
for title in titles:
    print(title.getText())
```

---

## âš–ï¸ Web Scraping Ã© Legal? <a href="#top" class="back-to-top-link" aria-label="Back to Top">â†‘</a>

- Raspe apenas dados pÃºblicos.
- Respeite o `robots.txt` e os termos do site.
- NÃ£o sobrecarregue os servidores (adicione atrasos se estiver raspando muitas pÃ¡ginas).
- Use os dados raspados de forma responsÃ¡vel.

---

## ğŸ¤– Selenium para Sites DinÃ¢micos <a href="#top" class="back-to-top-link" aria-label="Back to Top">â†‘</a>

Alguns sites carregam conteÃºdo com JavaScript ou exigem interaÃ§Ã£o. O Selenium permite que vocÃª controle um navegador real para lidar com esses casos.

Ao contrÃ¡rio do Beautiful Soup, que se limita a raspar dados, o Selenium permite a interaÃ§Ã£o com pÃ¡ginas da web, como digitar, clicar e rolar. Ele permite a automaÃ§Ã£o de aÃ§Ãµes contÃ­nuas e fluxos de trabalho inteiros de uma determinada tarefa ou trabalho. Ele efetivamente controla um navegador para realizar aÃ§Ãµes como um usuÃ¡rio humano.

O Selenium pode automatizar quase tudo que um humano pode fazer em um site, como preencher formulÃ¡rios, transferir informaÃ§Ãµes ou jogar jogos baseados na web.

### ğŸš— IntroduÃ§Ã£o ao Selenium WebDriver

* **O que Ã©:** O Selenium WebDriver Ã© uma ferramenta de automaÃ§Ã£o e teste bem conhecida para desenvolvedores da web.
* **Por que usÃ¡-lo (em vez do Beautiful Soup):** Ao contrÃ¡rio do Beautiful Soup, que se limita a raspar dados, o Selenium permite a interaÃ§Ã£o com pÃ¡ginas da web, como digitar, clicar e rolar. Ele permite a automaÃ§Ã£o de aÃ§Ãµes contÃ­nuas e fluxos de trabalho inteiros de uma determinada tarefa ou trabalho. Ele efetivamente controla um navegador para realizar aÃ§Ãµes como um usuÃ¡rio humano.
* **Capacidades:** O Selenium pode automatizar quase tudo que um humano pode fazer em um site, como preencher formulÃ¡rios, transferir informaÃ§Ãµes ou jogar jogos baseados na web.

### ğŸ”§ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o do Selenium

1.  **Instale o Navegador Chrome:** Embora o Selenium funcione com outros navegadores como Firefox ou Safari, o Chrome Ã© recomendado para consistÃªncia e uso das Ferramentas de Desenvolvedor do Chrome. Baixe o driver do Chrome em [chromedriver.chromium.org](https://chromedriver.chromium.org/downloads) e coloque-o em seu PATH.
2.  **Instale o Pacote Selenium:**
    * Importe `selenium` em seu arquivo Python (por exemplo, `main.py`).
    * Instale o pacote usando a opÃ§Ã£o de lÃ¢mpada fornecida em seu IDE.
```bash
pip install selenium
```
3.  **Importe o MÃ³dulo WebDriver:** Altere a declaraÃ§Ã£o de importaÃ§Ã£o para `from selenium import webdriver`.
4.  **Crie uma InstÃ¢ncia do Driver:** Inicialize um objeto de driver do Chrome: `driver = webdriver.Chrome()`.
    * **Chromedriver:** Ele atua como uma ponte entre o cÃ³digo Selenium Ğ¸ o navegador Chrome, dizendo ao Selenium como interagir com o navegador. Existem diferentes drivers para diferentes navegadores (por exemplo, Safari, Firefox).
5.  **Controle do Navegador:**
    * `driver.close()`: Fecha a aba ativa.
    * `driver.quit()`: Encerra o navegador inteiro. Ã‰ preferÃ­vel usar `quit()` apÃ³s concluir as tarefas para garantir uma nova instÃ¢ncia do navegador para futuras execuÃ§Ãµes.

### ğŸ” Exemplo: Abrir uma PÃ¡gina e Encontrar um Elemento
```python
from selenium import webdriver
from selenium.webdriver.common.by import By
import time as time_module

# Inicia o navegador
browser = webdriver.Chrome()
browser.get("https://www.python.org")

# Encontra elementos
event_times = browser.find_elements(By.CSS_SELECTOR, ".event-widget time")
event_names = browser.find_elements(By.CSS_SELECTOR, ".event-widget li a")

for time, name in zip(event_times, event_names):
    print(time.text, name.text)

# Espera 3 segundos antes de fechar
time_module.sleep(3)

browser.quit()
```

### ğŸ” Encontrando e Selecionando Elementos em um Site

**Localizando Elementos:**

O Selenium oferece vÃ¡rias estratÃ©gias para encontrar elementos HTML em uma pÃ¡gina da web. Depois de identificar um elemento com a ferramenta de inspeÃ§Ã£o do navegador, vocÃª pode copiar seu XPath ou outro identificador e usÃ¡-lo com:

* **MÃ©todo `find_element()`:** Usado para encontrar um Ãºnico elemento.
* **Classe `By`:** Importante para especificar a estratÃ©gia de localizaÃ§Ã£o (por exemplo, `By.CLASS_NAME`, `By.ID`, `By.NAME`, `By.LINK_TEXT`).
* **Exemplos:**
    * **Por Nome da Classe:** Para obter o preÃ§o de um item na Amazon, vocÃª pode encontrar elementos com classes como "a-price-whole" (para dÃ³lares) e "a-price-fraction" (para centavos).
    * **Acessando o ConteÃºdo de Texto:** Depois de encontrar um elemento, use `.text` para recuperar o conteÃºdo de texto dentro desse elemento HTML.
    * **Por Nome:** Ãštil para campos de entrada de formulÃ¡rio.
    * **Por Texto do Link:** Especificamente para clicar em links pelo texto visÃ­vel.
* **MÃ©todo `find_elements()`:** Para cada mÃ©todo `find_element()`, existe um `find_elements()` correspondente que retorna uma lista de todos os elementos correspondentes.
* **Inspecionando Elementos:** Use as Ferramentas de Desenvolvedor do Chrome (botÃ£o direito -> Inspecionar) para examinar a estrutura HTML e identificar IDs, nomes de classes ou outros atributos para elementos.

### ğŸ–±ï¸ Automatizando InteraÃ§Ãµes (DigitaÃ§Ã£o e Cliques)

* **Clicando em Elementos:**
    * Depois de identificar um elemento, use o mÃ©todo `.click()` no objeto do elemento.
    * O Selenium pode clicar em links com base em seu `LINK_TEXT`.
* **Digitando em Campos de Entrada:**
    * Primeiro, encontre o elemento do campo de entrada.
    * Use o mÃ©todo `.send_keys()` no objeto do elemento, passando a string que vocÃª deseja digitar.
* **Enviando Teclas Especiais:** Para enviar teclas como `Enter` ou `Return`, importe a classe `Keys` de `selenium.webdriver.common.keys`.


---

## ğŸ“ Desafio: Raspar os PrÃ³ximos Eventos do Python <a href="#top" class="back-to-top-link" aria-label="Back to Top">â†‘</a>

- Use o Selenium para abrir [python.org](https://www.python.org/)
- Extraia a data e o nome dos prÃ³ximos 5 eventos
- Armazene-os em um dicionÃ¡rio como:

```python
events = {
    0: {"time": "2025-06-11", "name": "PyCon"},
    1: {"time": "2025-06-18", "name": "DjangoCon"},
    # ...
}
```

---

## ğŸš€ Resumo <a href="#top" class="back-to-top-link" aria-label="Back to Top">â†‘</a>

- Use o Beautiful Soup para raspagem de HTML estÃ¡tico
- Use o Selenium para sites dinÃ¢micos e interativos
- Sempre respeite as regras e a Ã©tica do site

Agora vocÃª tem as ferramentas para coletar dados de quase qualquer site. Boa raspagem!
